CLASE.C5 <- predict(modelo_C5,data.test[,predictores] )
head(CLASE.C5)
PROBA.C5 <- predict(modelo_C5,data.test[,predictores],type="prob")
head(PROBA.C5)
PROBA.C5 <- PROBA.C5[,2]
#-------------------------------------------------
# Evaluando la performance del modelo
# Tabla de clasificación
library(gmodels)
CrossTable(x = data.test[,target], y= CLASE.C5,
prop.t=FALSE, prop.c=FALSE, prop.chisq = FALSE)
addmargins(table(Real=data.test[,target],Clase_Predicha=CLASE.C5))
prop.table(table(Real=data.test[,target],Clase_Predicha=CLASE.C5),1)
# Calcular el accuracy
accuracy.C5 <- mean(data.test[,target]==CLASE.C5) ; accuracy.C5
# Calcular el error de mala clasificación
error <- mean(data.test[,target]!=CLASE.C5) ; error
# Curva ROC usando el paquete caTools
library(caTools)
colAUC(PROBA.C5,data.test[,target],plotROC = TRUE)
abline(0, 1,col="red")
# Log-Loss
real <- as.numeric(data.test[,target])
real <- ifelse(real==2,1,0)
LogLoss(PROBA.C5,real)
################################
# 2. CART CON EL PAQUETE CARET #
################################
# Relación de modelos
library(caret)
#Relación de parámetros a ajustar de un modelo
modelLookup(model='rpart')
# Aplicando el modelo con Validación Cruzada Repetida
ctrl <- trainControl(method="repeatedcv",
repeats = 3, number=10)
set.seed(123)
modelo_cart <- train(data.train[,predictores],
data.train[,target],
preProcess=c("range"),
method = "rpart",
trControl = ctrl,
metric="Accuracy",
#tuneLength = 20)
tuneGrid = expand.grid(cp=seq(0,0.017,0.001)))
modelo_cart
modelo_cart$bestTune
modelo_cart$finalModel
plot(modelo_cart)
varImp(modelo_cart)
plot(varImp(modelo_cart))
modelo_cart$bestTune
modelo_cart$finalModel
library(rpart.plot)
rpart.plot(modelo_cart$finalModel, digits=-1, type=2, extra=101,cex = .7, nn=TRUE, shadow.col="gray")
CLASE.CART <- predict(modelo_cart,data.test[,predictores])
head(CLASE.CART)
PROBA.CART <- predict(modelo_cart,data.test[,predictores], type="prob")
PROBA.CART <- PROBA.CART[,2]
head(PROBA.CART)
#------------------------------------------------------------
# Evaluando la performance del modelo
# Tabla de clasificación
library(gmodels)
CrossTable(x = data.test[,target], y = CLASE.CART,
prop.t=FALSE, prop.c=FALSE, prop.chisq = FALSE)
addmargins(table(Real=data.test[,target],Clase_Predicha=CLASE.CART))
prop.table(table(Real=data.test[,target],Clase_Predicha=CLASE.CART),1)
# Calcular el accuracy
accuracy.CART <- mean(data.test[,target]==CLASE.CART) ; accuracy.CART
# Calcular el error de mala clasificación
error <- mean(data.test[,target]!=CLASE.CART) ; error
# Curva ROC usando el paquete caTools
library(caTools)
colAUC(PROBA.CART,data.test[,target],plotROC = TRUE)
abline(0, 1,col="red")
# Log-Loss
real <- as.numeric(data.test[,target])
real <- ifelse(real==2,1,0)
LogLoss(PROBA.CART,real)
###################################
# 3. BAGGING CON EL PAQUETE CARET #
###################################
# Relación de parámetros a ajustar de un modelo
modelLookup(model='treebag')
# Aplicando el modelo con Validación Cruzada Repetida
ctrl <- trainControl(method="repeatedcv",
repeats = 3, number=10)
set.seed(123)
modelo_bag <- train(data.train[,predictores],
data.train[,target],
preProcess=c("range"),
method = "treebag",
trControl = ctrl,
tuneLength = 5,
metric="Accuracy")
modelo_bag
modelo_bag$bestTune
modelo_bag$finalModel
# plot(modelo_bag)
# treebag no tiene parámetros para hacer tunning
varImp(modelo_bag)
plot(varImp(modelo_bag))
CLASE.BAG <- predict(modelo_bag,data.test[,predictores] )
head(CLASE.BAG)
PROBA.BAG <- predict(modelo_bag,data.test[,predictores], type="prob")
PROBA.BAG <- PROBA.BAG[,2]
head(PROBA.BAG)
#------------------------------------------------------------
# Evaluando la performance del modelo
# Tabla de clasificación
library(gmodels)
CrossTable(x = data.test[,target], y = CLASE.BAG,
prop.t=FALSE, prop.c=FALSE, prop.chisq = FALSE)
addmargins(table(Real=data.test[,target],Clase_Predicha=CLASE.BAG))
prop.table(table(Real=data.test[,target],Clase_Predicha=CLASE.BAG),1)
# Calcular el accuracy
accuracy.BAG <- mean(data.test[,target]==CLASE.BAG) ; accuracy.BAG
# Calcular el error de mala clasificación
error <- mean(data.test[,target]!=CLASE.BAG) ; error
# Curva ROC usando el paquete caTools
library(caTools)
colAUC(PROBA.BAG,data.test[,target],plotROC = TRUE)
abline(0, 1,col="red")
# Log-Loss
real <- as.numeric(data.test[,target])
real <- ifelse(real==2,1,0)
LogLoss(PROBA.BAG,real)
##########################################
# 4. RANDOM FOREST CON EL PAQUETE CARET  #
##########################################
# Relación de parámetros a ajustar de un modelo
modelLookup(model='rf')
# Aplicando el modelo con Validación Cruzada Repetida
ctrl <- trainControl(method="repeatedcv",
repeats = 3, number=10)
set.seed(123)
modelo_rf <- train(data.train[,predictores],
data.train[,target],
preProcess=c("range"),
method = "rf",
trControl = ctrl,
tuneLength = 5,
metric="Accuracy")
modelo_rf
modelo_rf$bestTune
modelo_rf$finalModel
plot(modelo_rf)
varImp(modelo_rf)
plot(varImp(modelo_rf))
CLASE.RF <- predict(modelo_rf,data.test[,predictores] )
head(CLASE.RF)
PROBA.RF <- predict(modelo_rf,data.test[,predictores], type="prob")
PROBA.RF <- PROBA.RF[,2]
head(PROBA.RF)
#------------------------------------------------------------
# Evaluando la performance del modelo
# Tabla de clasificación
library(gmodels)
CrossTable(x = data.test[,target], y = CLASE.RF,
prop.t=FALSE, prop.c=FALSE, prop.chisq = FALSE)
addmargins(table(Real=data.test[,target],Clase_Predicha=CLASE.RF))
prop.table(table(Real=data.test[,target],Clase_Predicha=CLASE.RF),1)
# Calcular el accuracy
accuracy.RF <- mean(data.test[,target]==CLASE.RF) ; accuracy.RF
# Calcular el error de mala clasificación
error <- mean(data.test[,target]!=CLASE.RF) ; error
# Curva ROC usando el paquete caTools
library(caTools)
colAUC(PROBA.RF,data.test[,target],plotROC = TRUE)
abline(0, 1,col="red")
# Log-Loss
real <- as.numeric(data.test[,target])
real <- ifelse(real==2,1,0)
LogLoss(PROBA.RF,real)
###########################################################
# 5. GBM (GRADIENT BOOSTING MACHINE) CON EL PAQUETE CARET #
###########################################################
# Relación de parámetros a ajustar de un modelo
modelLookup("gbm")
# Aplicando el modelo con Validación Cruzada Repetida
ctrl <- trainControl(method="repeatedcv",
repeats = 3, number=10)
set.seed(123)
modelo_gbm <- train(data.train[,predictores],
data.train[,target],
preProcess=c("range"),
method = "gbm",
tuneLength=2,
trControl=ctrl,
metric="Accuracy")
modelo_gbm
modelo_gbm$bestTune
modelo_gbm$finalModel
plot(modelo_gbm)
CLASE.GBM <- predict(modelo_gbm,data.test[,predictores] )
head(CLASE.GBM)
PROBA.GBM <- predict(modelo_gbm,data.test[,predictores], type="prob")
PROBA.GBM <- PROBA.GBM[,2]
head(PROBA.GBM)
#------------------------------------------------------------
# Evaluando la performance del modelo
# Tabla de clasificación
library(gmodels)
CrossTable(x = data.test[,target], y = CLASE.GBM,
prop.t=FALSE, prop.c=FALSE, prop.chisq = FALSE)
addmargins(table(Real=data.test[,target],Clase_Predicha=CLASE.GBM))
prop.table(table(Real=data.test[,target],Clase_Predicha=CLASE.GBM),1)
# Calcular el accuracy
accuracy.GBM <- mean(data.test[,target]==CLASE.GBM) ; accuracy.GBM
# Calcular el error de mala clasificación
error <- mean(data.test[,target]!=CLASE.GBM) ; error
# Curva ROC usando el paquete caTools
library(caTools)
colAUC(PROBA.GBM,data.test[,target],plotROC = TRUE)
abline(0, 1,col="red")
# Log-Loss
real <- as.numeric(data.test[,target])
real <- ifelse(real==2,1,0)
LogLoss(PROBA.GBM,real)
######################################
# 6. XGBOOSTING CON EL PAQUETE CARET #
######################################
# Relación de parámetros a ajustar de un modelo
modelLookup("xgbTree")
# Aplicando el modelo con Validación Cruzada Repetida
ctrl <- trainControl(method="repeatedcv",
repeats = 3, number=10)
set.seed(123)
modelo_xg <- train(data.train[,predictores],
data.train[,target],
preProcess=c("range"),
method = "xgbTree",
tuneLength=2,
trControl=ctrl,
metric="Accuracy")
#---------------------------------------------------------
# Para limpiar el workspace, por si hubiera algun dataset
# o informacion cargada
rm(list = ls())
dev.off()
options(scipen=999)
#---------------------------------------------------------
# Cambiar el directorio de trabajo
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
#-------------------------------------------------------------
# Paquetes
library(Boruta)
library(foreign)
library(caret)
install.packages("Boruta")
#---------------------------------------------------------
# Para limpiar el workspace, por si hubiera algun dataset
# o informacion cargada
rm(list = ls())
dev.off()
options(scipen=999)
#---------------------------------------------------------
# Cambiar el directorio de trabajo
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
#-------------------------------------------------------------
# Paquetes
library(Boruta)
library(foreign)
library(caret)
data.bank <- read.csv("Bank_Seleccion_Variables.csv",sep=";")
str(data.bank)
data.bank <- read.csv("Bank_Seleccion_Variables.csv",sep=";")
str(data.bank)
View(data.bank)
#---------------------------------------------------------------
# Para limpiar el workspace, por si hubiera algun dataset
# o informacion cargada
rm(list = ls())
dev.off()
options(scipen=999)
#---------------------------------------------------------------
# Cambiar el directorio de trabajo
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
cat("\014")
library(rstudioapi)
library(tictoc)
library(data.table)
library(funModeling)
library(h2o)
library(caTools)
library(dplyr)
library(tidyr)
library(ggplot2)
library(MLmetrics)
library(plotROC)
install.packages("tictoc")
install.packages("funModeling")
install.packages("h2o")
install.packages("plotROC")
library(rstudioapi)
library(tictoc)
library(data.table)
library(funModeling)
library(h2o)
library(caTools)
library(dplyr)
library(tidyr)
library(ggplot2)
library(MLmetrics)
library(plotROC)
install.packages("plotROC")
library(rstudioapi)
library(tictoc)
library(data.table)
library(funModeling)
library(h2o)
library(caTools)
library(dplyr)
library(tidyr)
library(ggplot2)
library(MLmetrics)
library(plotROC)
install.packages("h2o")
library(rstudioapi)
library(tictoc)
library(data.table)
library(funModeling)
library(h2o)
library(caTools)
library(dplyr)
library(tidyr)
library(ggplot2)
library(MLmetrics)
library(plotROC)
library(tictoc)
tic()
my_data <- read.csv("ccFraud_custom.csv",
sep=";",
stringsAsFactors = T)
toc()
library(data.table)
tic()
data <- fread("ccFraud_custom.csv",
sep= ";",
stringsAsFactors = T)
toc()
str(data)
table(data$FraudFlag)
prop.table(table(data$FraudFlag))*100
#---------------------------------------------------------------
# Explorando las variables predictoras
library(funModeling)
cross_plot(data,
input="NumOfCards",
target="FraudFlag",
plot_type = "percentual")
cross_plot(data,
input="OutsBal",
target="FraudFlag",
plot_type = "percentual")
cross_plot(data,
input="DomesTransc",
target="FraudFlag",
plot_type = "percentual")
cross_plot(data,
input="IntTransc",
target="FraudFlag",
plot_type = "percentual")
cross_plot(data,
input="Gender",
target="FraudFlag",
plot_type = "percentual")
cross_plot(data,
input="CardType",
target="FraudFlag",
plot_type = "percentual")
library(h2o)
# Creación de un cluster local con todos los cores disponibles.
h2o.init(ip = "localhost",
# -1 indica que se empleen todos los cores disponibles.
nthreads = -1,
# Máxima memoria disponible para el cluster.
max_mem_size = "4g")
library(h2o)
# Creación de un cluster local con todos los cores disponibles.
h2o.init(ip = "localhost",
# -1 indica que se empleen todos los cores disponibles.
nthreads = -1,
# Máxima memoria disponible para el cluster.
max_mem_size = "4g")
library(h2o)
# Creación de un cluster local con todos los cores disponibles.
h2o.init(ip = "localhost",
# -1 indica que se empleen todos los cores disponibles.
nthreads = -1,
# Máxima memoria disponible para el cluster.
max_mem_size = "4g")
# 1. Transferencia a H2O desde el workspace
datos_h2o <- as.h2o(data)
# 2. Carga de datos en el cluster H2o desde archivo
datos_h2o_2 <- h2o.importFile(path = "ccFraud_custom.csv",
sep = ",",
header= TRUE)
h2o.init(ip = "localhost",
# -1 indica que se empleen todos los cores disponibles.
nthreads = -1,
# Máxima memoria disponible para el cluster.
max_mem_size = "4g")
h2o.init(ip = "localhost",
# -1 indica que se empleen todos los cores disponibles.
nthreads = -1,
# Máxima memoria disponible para el cluster.
max_mem_size = "4g")
h20.init()
h2o.init()
h2o.init(ip = "localhost",
# -1 indica que se empleen todos los cores disponibles.
nthreads = -1,
# Máxima memoria disponible para el cluster.
max_mem_size = "4g")
tic()
toc()
rf2_gridperf <- h2o.getGrid(grid_id = "rf2_grid",
sort_by = "accuracy",
decreasing = TRUE)
options(scipen=999)
options(digits=3)
dat = read.csv("BancoCliente.csv", header = TRUE, row.names = 'ID_Cliente')
dat = read.csv("BancoCliente.csv", header = TRUE, row.names = 'ID_Cliente')
dat = read.csv("BancoCliente.csv", header = TRUE, row.names = 'ID_Cliente')
dat = read.csv("BancoCliente.csv", header = TRUE, row.names = 'ID_Cliente')
dat = read.csv("BancoCliente.csv", header = TRUE, row.names = 'ID_Cliente')
dat = read.csv("BancoCliente.csv", header = TRUE, row.names = 'ID_Cliente')
getwd()
setwd('~/Documents/Projects/Maestria/Multivariantes/Examen_Parcial_PCA/AnalisisPCA')
dat = read.csv("BancoCliente.csv", header = TRUE, row.names = 'ID_Cliente')
attach(dat)
View(dat)
View(dat)
install.packages(c("FactoMineR", "factoextra"))
library("FactoMineR")
library("factoextra")
dat = read.csv("BancoCliente.csv", header = TRUE, row.names = 'ID_Cliente')
head(dat)
bancoCliente = read.csv("BancoCliente.csv", header = TRUE, row.names = 'ID_Cliente')
attach(bancoCliente)
princomp(bancoCliente)
fviz_eig(princomp(bancoCliente), addlabels = TRUE, ylim = c(0, 50))
bancoCliente
res.pca <- PCA(bancoCliente, graph = FALSE)
print(res.pca)
eig.val <- get_eigenvalue(res.pca)
eig.val
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 20))
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 20))
eig.val
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 20), ncp = 19)
var <- get_pca_var(res.pca)
var
# Coordinates
head(var$coord)
# Cos2: quality on the factore map
head(var$cos2)
# Contributions to the principal components
head(var$contrib)
fviz_pca_var(res.pca, col.var = "black")
res.pca <- PCA(bancoCliente)
res.pca <- PCA(bancoCliente, graph = FALSE)
print(res.pca)
eig.val
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 20), ncp = 19)
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 15), ncp = 19)
fviz_pca_var(res.pca, col.var = "black")
corrplot(var$cos2, is.corr=FALSE)
install.packages("corrplot")
var <- get_pca_var(res.pca)
var
corrplot(var$cos2, is.corr=FALSE)
library("corrplot")
corrplot(var$cos2, is.corr=FALSE)
head(var$coord)
head(var$cos2)
head(var$contrib)
fviz_pca_var(res.pca, col.var = "black")
head(var$coord)
res.pca
head(var$coord)
head(var$cos2)
head(var$contrib)
corrplot(var$cos2, is.corr=FALSE)
var <- get_pca_var(res.pca)
res.pca
get_pca(res.pca, "ind") # Results for individuals
get_pca(res.pca, "ind")$contrib # Results for individuals
var <- get_pca_var(res.pca)
var
# Coordinates
head(var$coord)
# Cos2: quality on the factore map
head(var$cos2)
# Contributions to the principal components
head(var$contrib)
corrplot(var$cos2, is.corr=FALSE)
fviz_cos2(res.pca, choice = "var")
fviz_cos2(res.pca, choice = "var", axes = 1:2)
fviz_cos2(res.pca, choice = "var", axes = 1:2)
fviz_cos2(res.pca, choice = "var", axes = 2:3)
fviz_cos2(res.pca, choice = "var", axes = 6:7)
fviz_pca_var(res.pca, col.var = "black")
fviz_pca_var(res.pca, col.var = "black")
fviz_pca_var(res.pca, col.var = "black")
install.packages("CCA")
??CCA::cc
